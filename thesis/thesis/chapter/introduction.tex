\chapter{Introduction}\label{chapter:introduction}
%
Human vision is inherently selective. Rather than processing the entire visual field uniformly, 
the human eye relies on a foveated view, where high-resolution vision is concentrated in a small central region (the fovea), 
while the surrounding peripheral vision is of lower resolution.
Humans sequentially direct their gaze towards interesting or task-relevant regions of a scene,
integrating information over time to form a coherent understanding of their environment.
This mechanism of selective attention allows humans to efficiently process complex visual scenes under limited computational resources.\\\\
%
In contrast, most artificial vision systems process visual inputs in a uniform manner,
requiring high computational resources to achieve comparable performance to human vision.
They also usually only use a single feedforward pass to process an image, leading to limited interpretability and adaptability to changing environments.\\\\
%
Research in active vision and attention-based reinforcement learning has begun to address these limitations.
Models such as the Recurrent Attention Model (RAM) \citep{mnih2014recurrentmodelsvisualattention} and its variants have demonstrated
the potential of foveated vision and sequential attention mechanisms in artificial agents.
In addition to these attention mechanisms, auxiliary tasks such as image reconstruction have been shown to improve the stability and performance of reinforcement learning agents \citep{jaderberg2016reinforcementlearningunsupervisedauxiliary}.\\\\
%
In this thesis, we propose a novel architecture that combines a recurrent visual attention mechanism with an auxiliary reconstruction task to enable artificial agents to efficiently process visual information.
Our agent will be trained to learn two policies, a decision making policy that classifies the input based on the glimpses seen so far, and a sensory policy that decides where to look next. 
This sensory policy will move the gaze to points of interest on the input image, integrating information over time to enable the decision making policy to make accurate classifications.
We want to combine the benefits of active vision with the stabilizing effects of auxiliary tasks to create a robust and interpretable model for visual reasoning tasks.\\\\
%
This work will be a foundation that can be built upon and improved in future research and adapted to more difficult tasks, such as dynamic environments or real-world applications.