# Submit from the repository root: condor_submit train.sub
BASE_DIR                = .
CONFIG_MODULE           = configL

WANDB_PROJECT           = GazeControl
WANDB_ENTITY            = 
WANDB_MODE              = online
WANDB_API_KEY           = 
RUN_NAME                = train_$(Cluster).$(Process)

# Python interpreter to use (virtualenv recommended)
PYTHON                  = .venv/bin/python

# Training run knobs
USE_PRETRAINED_FLAG     = --use-pretrained
LOAD_FULL_FLAG          = 
NO_RL_FLAG              = 
EXTRA_ARGS              = 

universe                = vanilla
executable              = $(PYTHON)
initialdir              = $(BASE_DIR)
arguments               = train.py --config $(CONFIG_MODULE) $(USE_PRETRAINED_FLAG) $(LOAD_FULL_FLAG) $(NO_RL_FLAG) --wandb --wandb-project $(WANDB_PROJECT) --wandb-entity $(WANDB_ENTITY) --wandb-run-name $(RUN_NAME) $(EXTRA_ARGS)
log                     = condor_logs/train.$(Cluster).$(Process).log
output                  = condor_logs/train.$(Cluster).$(Process).out
error                   = condor_logs/train.$(Cluster).$(Process).err
request_gpus            = 1
request_cpus            = 6
request_memory          = 12 GB
getenv                  = True
stream_output           = True
stream_error            = True
requirements            = (CUDADeviceName =!= UNDEFINED)

# Optional: route temporary files and pip cache to data/scratch to avoid HOME quota
TMPDIR                  = 
PIP_CACHE_DIR           = 
environment             = "WANDB_API_KEY=$(WANDB_API_KEY); WANDB_MODE=$(WANDB_MODE); WANDB_PROJECT=$(WANDB_PROJECT); WANDB_ENTITY=$(WANDB_ENTITY); RUN_NAME=$(RUN_NAME); TMPDIR=$(TMPDIR); PIP_CACHE_DIR=$(PIP_CACHE_DIR)"

queue 1
