# Submit from the repository root: condor_submit train.sub
BASE_DIR                = .
CONFIG_MODULE           = config_maze128

WANDB_PROJECT           = GazeControl
WANDB_ENTITY            = FlorentinDoll
WANDB_MODE              = online
WANDB_API_KEY           = 
RUN_NAME                = train_maze128$(Cluster).$(Process)

# Python interpreter to use (virtualenv recommended)
PYTHON                  = .venv/bin/python

# Training run knobs
USE_PRETRAINED_FLAG     = --use-pretrained
LOAD_FULL_FLAG          = 
NO_RL_FLAG              =
EXTRA_ARGS              = 

universe                = vanilla
executable              = $(PYTHON)
initialdir              = $(BASE_DIR)
arguments               = -u train.py --config $(CONFIG_MODULE) $(USE_PRETRAINED_FLAG) $(LOAD_FULL_FLAG) $(NO_RL_FLAG) --wandb --wandb-project $(WANDB_PROJECT) --wandb-entity $(WANDB_ENTITY) --wandb-run-name $(RUN_NAME) $(EXTRA_ARGS)
log                     = condor_logs/train.$(Cluster).$(Process).log
output                  = condor_logs/train.$(Cluster).$(Process).out.log
error                   = condor_logs/train.$(Cluster).$(Process).err.log
request_gpus            = 1
request_cpus            = 4
request_memory          = 8 GB
getenv                  = True
stream_output           = True
stream_error            = True
requirements            = (CUDADeviceName =!= UNDEFINED)
require_gpus = Capability >= 8.0

# Optional: route temporary files and pip cache to data/scratch to avoid HOME quota
TMPDIR                  = 
PIP_CACHE_DIR           = 
environment             = "WANDB_MODE=$(WANDB_MODE) WANDB_PROJECT=$(WANDB_PROJECT) WANDB_ENTITY=$(WANDB_ENTITY) RUN_NAME=$(RUN_NAME) TMPDIR=$(TMPDIR) PIP_CACHE_DIR=$(PIP_CACHE_DIR)"

queue 1
